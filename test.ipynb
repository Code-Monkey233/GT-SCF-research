{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from collections import OrderedDict\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import flwr as fl\n",
    "from fl_preprocessing import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from fl_model import get_model\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "N_FEATURES = 11\n",
    "INPUT_DIM = N_FEATURES #check，此处特征值的设定不一定合理\n",
    "OUTPUT_DIM = 1\n",
    "HIDDEN_DIM = 64\n",
    "LAYER_DIM = 3\n",
    "BATCH_SIZE = 64\n",
    "DROPOUT = 0.2\n",
    "EPOCH = 50\n",
    "LEARNING_RATE = 0.001\n",
    "WEIGHT_DECAY = 0.0001\n",
    "# FL Settings  训练7轮，客户端数目为5\n",
    "ROUND = 7\n",
    "NUM_CLIENTS = 2\n",
    "#from myconstants import *  #本篇中的所有常量引用来源\n",
    "# Models chosen from rnn, lstm #定义了LSTM模型的基本结构\n",
    "MODEL = \"lstm\"\n",
    "MODEL_PARAMS = {\"input_dim\": INPUT_DIM,\n",
    "                \"hidden_dim\": HIDDEN_DIM,\n",
    "                \"layer_dim\": LAYER_DIM,\n",
    "                \"output_dim\": OUTPUT_DIM,\n",
    "                \"dropout_prob\": DROPOUT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Occupancy  lag1  lag2  lag3  lag4  lag5\n",
      "Datetime                                                    \n",
      "2022-06-19 00:25:00         12  12.0  12.0  12.0  12.0  12.0\n",
      "2022-06-19 00:30:00         12  12.0  12.0  12.0  12.0  12.0\n",
      "2022-06-19 00:35:00         12  12.0  12.0  12.0  12.0  12.0\n",
      "2022-06-19 00:40:00         12  12.0  12.0  12.0  12.0  12.0\n",
      "2022-06-19 00:45:00         12  12.0  12.0  12.0  12.0  12.0\n",
      "...                        ...   ...   ...   ...   ...   ...\n",
      "2022-07-18 23:35:00         18  18.0  18.0  18.0  18.0  18.0\n",
      "2022-07-18 23:40:00         18  18.0  18.0  18.0  18.0  18.0\n",
      "2022-07-18 23:45:00         18  18.0  18.0  18.0  18.0  18.0\n",
      "2022-07-18 23:50:00         18  18.0  18.0  18.0  18.0  18.0\n",
      "2022-07-18 23:55:00         16  18.0  18.0  18.0  18.0  18.0\n",
      "\n",
      "[8635 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "X_train_arr, X_test_arr, y_train_arr, y_test_arr, X_test, scaler = preprocessing('102.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6908, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Occupancy  lag1  lag2  lag3  lag4  lag5\n",
      "Datetime                                                    \n",
      "2022-06-19 00:25:00         12  12.0  12.0  12.0  12.0  12.0\n",
      "2022-06-19 00:30:00         12  12.0  12.0  12.0  12.0  12.0\n",
      "2022-06-19 00:35:00         12  12.0  12.0  12.0  12.0  12.0\n",
      "2022-06-19 00:40:00         12  12.0  12.0  12.0  12.0  12.0\n",
      "2022-06-19 00:45:00         12  12.0  12.0  12.0  12.0  12.0\n",
      "...                        ...   ...   ...   ...   ...   ...\n",
      "2022-07-18 23:35:00         18  18.0  18.0  18.0  18.0  18.0\n",
      "2022-07-18 23:40:00         18  18.0  18.0  18.0  18.0  18.0\n",
      "2022-07-18 23:45:00         18  18.0  18.0  18.0  18.0  18.0\n",
      "2022-07-18 23:50:00         18  18.0  18.0  18.0  18.0  18.0\n",
      "2022-07-18 23:55:00         16  18.0  18.0  18.0  18.0  18.0\n",
      "\n",
      "[8635 rows x 6 columns]\n",
      "                     Occupancy  lag1  lag2  lag3  lag4  lag5\n",
      "Datetime                                                    \n",
      "2022-06-19 00:25:00         12  12.0  12.0  12.0  12.0  12.0\n",
      "2022-06-19 00:30:00         12  12.0  12.0  12.0  12.0  12.0\n",
      "2022-06-19 00:35:00         12  12.0  12.0  12.0  12.0  12.0\n",
      "2022-06-19 00:40:00         13  12.0  12.0  12.0  12.0  12.0\n",
      "2022-06-19 00:45:00         13  13.0  12.0  12.0  12.0  12.0\n",
      "...                        ...   ...   ...   ...   ...   ...\n",
      "2022-07-18 23:35:00         10  10.0   9.0   9.0   9.0   9.0\n",
      "2022-07-18 23:40:00         11  10.0  10.0   9.0   9.0   9.0\n",
      "2022-07-18 23:45:00         11  11.0  10.0  10.0   9.0   9.0\n",
      "2022-07-18 23:50:00         11  11.0  11.0  10.0  10.0   9.0\n",
      "2022-07-18 23:55:00         11  11.0  11.0  11.0  10.0  10.0\n",
      "\n",
      "[8635 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "def load_data(batch_size: int):\n",
    "    datasets = [\"102.csv\", \"1162.csv\"]\n",
    "    train_loaders = []\n",
    "    test_loaders = []\n",
    "    nums_examples = []\n",
    "    nums_features = []\n",
    "    X_tests = []\n",
    "    scalers = []\n",
    "\n",
    "    for path in datasets:\n",
    "        X_train_arr, X_test_arr, y_train_arr, y_test_arr, X_test, scaler = preprocessing(path)\n",
    "        #定义预处理函数preprocessing\n",
    "        train_features = torch.Tensor(X_train_arr).to(DEVICE)\n",
    "        train_targets = torch.Tensor(y_train_arr).to(DEVICE)\n",
    "\n",
    "        test_features = torch.Tensor(X_test_arr).to(DEVICE)\n",
    "        test_targets = torch.Tensor(y_test_arr).to(DEVICE)\n",
    "\n",
    "        train = TensorDataset(train_features, train_targets)\n",
    "        test = TensorDataset(test_features, test_targets)\n",
    "\n",
    "        train_loader = DataLoader(train, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "        test_loader = DataLoader(test, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "        num_examples = {\"trainset\": len(X_train_arr), \"testset\":len(X_test_arr)}\n",
    "        num_features = X_train_arr.shape[1]\n",
    "\n",
    "        train_loaders.append(train_loader)\n",
    "        test_loaders.append(test_loader)\n",
    "        nums_examples.append(num_examples)\n",
    "        nums_features.append(num_features)\n",
    "        X_tests.append(X_test)\n",
    "        scalers.append(scaler)\n",
    "    return train_loaders, test_loader, nums_examples, nums_features, X_tests, scalers\n",
    "\n",
    "def train(net, train_loader, epochs):\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "    def train_step(x, y):\n",
    "        net.train()\n",
    "        yhat = net(x) #make prediction\n",
    "        loss = loss_fn(y, yhat) #compute loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        return loss.item()\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch = x_batch.view([BATCH_SIZE, -1, N_FEATURES]).to(DEVICE)\n",
    "            y_batch = y_batch.to(DEVICE)\n",
    "            loss = train_step(x_batch, y_batch)\n",
    "\n",
    "def test(net, testloader, X_test, scaler):\n",
    "    loss = 0\n",
    "    criteron = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        values = []\n",
    "        for x_test, y_test in testloader:\n",
    "            x_test = x_test.view([BATCH_SIZE, -1, N_FEATURES]).to(DEVICE)\n",
    "            y_test=y_test.to(DEVICE)\n",
    "            net.eval()\n",
    "            yhat = net(x_test)\n",
    "            predictions.append(yhat.cpu().numpy())\n",
    "            values.append(y_test.cpu().numpy())\n",
    "            loss += criteron(yhat, y_test)\n",
    "\n",
    "    df_result = format_predictions(predictions, values, X_test, scaler)\n",
    "    rmse = mean_squared_error(df_result.value, df_result.prediction, squared=False)\n",
    "    return loss, rmse\n",
    "\n",
    "def inverse_transform(scaler, df, columns):\n",
    "    for col in columns:\n",
    "        df[col] = scaler.inverse_transform(df[col])\n",
    "    return df\n",
    "\n",
    "def format_predictions(predictions, values, df_test, scaler):\n",
    "    vals = np.concatenate(values, axis=0).ravel()\n",
    "    preds = np.concatenate(predictions, axis=0).ravel()\n",
    "    df_result = pd.DataFrame(data={\"value\": vals, \"prediction\": preds}, index=df_test.head(len(vals)).index)\n",
    "    df_result = df_result.sort_index()\n",
    "    df_result = inverse_transform(scaler, df_result, [[\"value\", \"prediction\"]])\n",
    "    return df_result\n",
    "\n",
    "trainloaders, testloaders, nums_examples, nums_features, X_tests, scalers = load_data(batch_size=BATCH_SIZE)\n",
    "\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fdde875ca60>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloaders[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, net, trainloader, testloader, num_examples, num_features, X_test, scaler):\n",
    "        self.cid = cid\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.testloader = testloader\n",
    "        self.num_examples = num_examples\n",
    "        self.num_features = num_features\n",
    "        self.X_test = X_test\n",
    "        self.scaler = scaler\n",
    "    \n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.cid}] get_parameters\")\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=EPOCH)\n",
    "        return self.get_parameters(config={}), self.num_examples[\"trainset\"], {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, rmse = test(self.net, self.testloader, self.X_test, self.scaler)\n",
    "        print(\"loss \", loss)\n",
    "        print(\"rmse \", rmse)\n",
    "        return float(loss), self.num_examples[\"testset\"], {\"rmse\": float(rmse)}\n",
    "\n",
    "def client_fn(cid) -> Client:  #client fn需要定义训练模型使用的网络，数据loader\n",
    "    net = get_model(MODEL, MODEL_PARAMS).to(DEVICE)  #定义将要使用的模型\n",
    "    trainloader = trainloaders[int(cid)]   #训练数据加载\n",
    "    testloader = testloaders[int(cid)]   #测试数据加载\n",
    "    num_examples = nums_examples[int(cid)]   #实例数\n",
    "    num_features = nums_features[int(cid)]   #特征数\n",
    "    X_test = X_tests[int(cid)]   #from load_data\n",
    "    scaler = scalers[int(cid)]   #from load_data\n",
    "    #返回值是flower定义好的client类\n",
    "    return Client(cid, net, trainloader, testloader, num_examples, num_features, X_test, scaler)  #return CLient Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_resources = None \n",
    "if DEVICE.type == \"cuda\":   \n",
    "  client_resources = {\"num_gpus\": 1}\n",
    "\n",
    "# FedAVG/FedProx algorithm\n",
    "class CustomStrategy(fl.server.strategy.FedAvg):\n",
    "    def aggregate_fit(self, server_round, results, failures):\n",
    "\n",
    "        # Call aggregate_fit from base class (FedAvg) to aggregate parameters and metrics\n",
    "        aggregated_parameters, aggregated_metrics = super().aggregate_fit(server_round, results, failures)\n",
    "\n",
    "        if aggregated_parameters is not None:\n",
    "            # Convert `Parameters` to `List[np.ndarray]`\n",
    "            aggregated_ndarrays: List[np.ndarray] = fl.common.parameters_to_ndarrays(aggregated_parameters)\n",
    "            # Save aggregated_ndarrays\n",
    "            print(f\"Saving round {server_round} aggregated_ndarrays...\")\n",
    "            np.savez(f\"./flower/savedmodels/round-{server_round}-weights.npz\", *aggregated_ndarrays)\n",
    "\n",
    "        return aggregated_parameters, aggregated_metrics\n",
    "\n",
    "    def aggregate_evaluate(self, server_round, results, failures):\n",
    "        \"\"\"Aggregate evaluation rmse using weighted average.\"\"\"\n",
    "\n",
    "        if not results:\n",
    "            return None, {}\n",
    "\n",
    "        # Call aggregate_evaluate from base class (FedAvg) to aggregate loss and metrics\n",
    "        aggregated_loss, aggregated_metrics = super().aggregate_evaluate(server_round, results, failures)\n",
    "\n",
    "        # Weigh rmse of each client by number of examples used\n",
    "        rmses = [r.metrics[\"rmse\"] * r.num_examples for _, r in results]\n",
    "        examples = [r.num_examples for _, r in results]\n",
    "\n",
    "        # Aggregate and print custom metric\n",
    "        aggregated_rmse = sum(rmses) / sum(examples)\n",
    "        print(f\"Round {server_round} rmse aggregated from client results: {aggregated_rmse}\")\n",
    "\n",
    "        # Return aggregated loss and metrics (i.e., aggregated rmse)\n",
    "        return aggregated_loss, {\"rmse\": aggregated_rmse}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # strategy = CustomStrategy(proximal_mu=1)\n",
    "    strategy = CustomStrategy()\n",
    "\n",
    "    fl.simulation.start_simulation(\n",
    "        client_fn=client_fn,\n",
    "        num_clients=NUM_CLIENTS,\n",
    "        config=fl.server.ServerConfig(num_rounds=ROUND),\n",
    "        client_resources=client_resources,\n",
    "        strategy = strategy,\n",
    "        ray_init_args = {\"include_dashboard\": False}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3., 4., 5., 6.]])\n",
      "tensor([[1., 2., 3., 4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.Tensor([[[1,2,3],[4,5,6]]])\n",
    "b=torch.Tensor([1,2,3,4,5,6])\n",
    "\n",
    "print(a.view(1,6))\n",
    "print(b.view(1,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flower",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
